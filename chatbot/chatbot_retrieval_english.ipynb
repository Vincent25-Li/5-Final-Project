{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "\n",
    "engine = db.create_engine('mysql+pymysql://root:root@localhost:3306/chatbot_english')\n",
    "conn = engine.connect()\n",
    "metadata = db.MetaData()\n",
    "table_category = db.Table('table_category', metadata, autoload=True, autoload_with=engine)\n",
    "table_qa_pairs = db.Table('table_qa_pairs', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# load sql data in table 'table_category' and 'table_qa_pairs'\n",
    "category = conn.execute(table_category.select()).fetchall()\n",
    "qa_pairs = conn.execute(table_qa_pairs.select()).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_qa_pairs = pd.DataFrame(qa_pairs)\n",
    "df_qa_pairs.columns = table_qa_pairs.columns.keys()\n",
    "category_dict = {i:category for (i, category) in category}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x113b5a908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa_pairs['category'] = df_qa_pairs['FK_category'].map(category_dict)\n",
    "category_number = len(df_qa_pairs['category'].unique())\n",
    "bins = np.arange(category_number+1) - 0.5\n",
    "df_qa_pairs['category'].hist(\n",
    "    grid=False, xlabelsize=18, ylabelsize=18, xrot=45, figsize=(20, 10), bins=bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training data x and y \n",
    "PK_question = df_qa_pairs['PK_qa_pairs'].to_numpy().reshape(-1, 1)\n",
    "x_question = df_qa_pairs['question'].to_numpy().reshape(-1, 1) # training data x\n",
    "y_category = df_qa_pairs['FK_category'].to_numpy().reshape(-1, 1) # training data y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# transform raw text into TFIDF\n",
    "def data_process(sentences):\n",
    "\n",
    "    sentences_wo_p = np.array(list(map(\n",
    "        lambda x: [re.sub('[^\\w\\s]', '', x[0])], sentences \n",
    "    ))) # remove punctuations\n",
    "    \n",
    "    sentences_split = np.array(list(map(\n",
    "        lambda x: x[0].split(), sentences_wo_p\n",
    "    ))) # split sentence into words\n",
    "    \n",
    "    st = PorterStemmer()\n",
    "    words_stemmed = np.array(list(map(\n",
    "        lambda x: [st.stem(word.lower()) for word in x], sentences_split\n",
    "    ))) # stemming of word\n",
    "    sentences_processed = np.array(list(map(\n",
    "        lambda x: ' '.join(x), words_stemmed\n",
    "    )))\n",
    "    return sentences_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# TfidfVectorizer is equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "\n",
    "x_question_processed = data_process(x_question)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.3)\n",
    "\n",
    "x_train = vectorizer.fit_transform(x_question_processed)\n",
    "y_train = y_category\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=0, stratify=y_train)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyuming/.pyenv/versions/3.6.8/envs/chatbot/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "dest = os.path.join('chatbot_model')\n",
    "if not os.path.exists(dest):\n",
    "    os.mkdir(dest)\n",
    "pickle.dump(clf,\n",
    "    open(os.path.join(dest, 'topic_clf_RF.pkl'), 'wb'),\n",
    "    protocol=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=0, stratify=y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = sum(y_pred == np.ravel(y_test))/len(y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi how may I help you: hi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am doing well.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "user_input = input('Hi how may I help you: ')\n",
    "user_input_processed = data_process(np.array([user_input]).reshape(-1, 1))\n",
    "\n",
    "user_input_vectorized = vectorizer.transform(user_input_processed)\n",
    "user_pred = clf.predict(user_input_vectorized)\n",
    "\n",
    "search_idx = y == user_pred\n",
    "search_question = x[np.ravel(search_idx)]\n",
    "search_PK_qa_pairs = PK_question[search_idx]\n",
    "\n",
    "similarity = cosine_similarity(search_question, user_input_vectorized)\n",
    "PK_qa_pairs = search_PK_qa_pairs[np.argmax(similarity)]\n",
    "\n",
    "reply = df_qa_pairs.loc[PK_qa_pairs, 'answer']\n",
    "reply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
