{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tripblog\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xA5x\\\\xA5_\\\\xBC\\\\xD0...' for column 'VARIABLE_VALUE' at row 1\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as db\n",
    "\n",
    "engine = db.create_engine('mysql+pymysql://root:root@localhost:3306/chatbot_chinese')\n",
    "conn = engine.connect()\n",
    "metadata = db.MetaData()\n",
    "table_category = db.Table('table_category', metadata, autoload=True, autoload_with=engine)\n",
    "table_qa_pairs = db.Table('table_qa_pairs', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# load sql data in table 'table_category' and 'table_qa_pairs'\n",
    "category = conn.execute(table_category.select()).fetchall()\n",
    "qa_pairs = conn.execute(table_qa_pairs.select()).fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data in dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_qa_pairs = pd.DataFrame(qa_pairs)\n",
    "df_qa_pairs.columns = table_qa_pairs.columns.keys()\n",
    "category_dict = {i:category for (i, category) in category}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.set_dictionary('dict.txt')\n",
    "with open('stops_specail.txt', 'r', encoding='utf8') as f: \n",
    "    stops = f.read().split('\\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\User\\Desktop\\Final-Project_TripBlog\\chatbot\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.u17c4573158338ce3b996b9f10ee53c44.cache\n",
      "Loading model cost 0.385 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "all_terms = []\n",
    "def preprocess(item):\n",
    "    terms = [t for t in jieba.cut(item, cut_all=False)]\n",
    "    all_terms.extend(terms)\n",
    "    return terms\n",
    "\n",
    "def preprocess_all(item):\n",
    "    terms = [t for t in jieba.cut(item, cut_all=True)]\n",
    "    all_terms.extend(terms)\n",
    "    return terms\n",
    "\n",
    "df_qa_pairs['processed'] = df_qa_pairs['question'].apply(preprocess_all)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(termindex) 883\n",
      "['', '形狀', '存在', '怎', '肯定', '生活', '確定', '罷了', '笑', '哥']\n"
     ]
    }
   ],
   "source": [
    "# 建立termindex: 將all_terms取出不重複的詞彙，並轉換型別為list(避免順序亂掉)\n",
    "termindex = list(set(all_terms))\n",
    "\n",
    "print(\"len(termindex)\", len(termindex))\n",
    "print(termindex[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883\n",
      "['', '形狀', '存在', '怎', '肯定', '生活', '確定', '罷了', '笑', '哥']\n",
      "[1.5381567104291367, 6.366470447731438, 5.673323267171493, 6.366470447731438, 6.366470447731438, 6.366470447731438, 5.673323267171493, 6.366470447731438, 5.673323267171493, 6.366470447731438]\n"
     ]
    }
   ],
   "source": [
    "# 建立IDF vector\n",
    "Doc_Length = len(df_qa_pairs)  ## 計算出共有幾篇文章\n",
    "Idf_vector = []  ## 初始化IDF向量\n",
    "for term in termindex:  ## 對index中的詞彙跑回圈\n",
    "    num_of_doc_contains_term = 0  ## 計算有機篇文章出現過這個詞彙\n",
    "    for terms in df_qa_pairs['processed']:\n",
    "        if term in terms:\n",
    "            num_of_doc_contains_term += 1\n",
    "    idf = np.log(Doc_Length/num_of_doc_contains_term)  ## 計算該詞彙的IDF值\n",
    "    Idf_vector.append(idf)\n",
    "\n",
    "\n",
    "\n",
    "print(len(Idf_vector))\n",
    "print(termindex[:10])\n",
    "print(Idf_vector[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# 建立document vector\n",
    "def terms_to_vector(terms):  ## 定義把terms轉換成向量的function\n",
    "    ## 建立一條與termsindex等長、但值全部為零的向量(hint:dtype=np.float32)\n",
    "    vector = np.zeros_like(termindex, dtype=np.float32)  \n",
    "    \n",
    "    for term, count in Counter(terms).items():\n",
    "        # 計算vector上每一個字的tf值\n",
    "        try:\n",
    "            vector[termindex.index(term)] = count\n",
    "        except ValueError:\n",
    "            count = 0\n",
    "    \n",
    "    # 計算tfidf，element-wise的將vector與Idf_vector相乘\n",
    "    vector = vector * Idf_vector\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_qa_pairs['vector'] = df_qa_pairs['processed'].apply(terms_to_vector)  ## 將上面定義的function，套用在每一筆資料的terms欄位上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582, 883)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PK_question = df_qa_pairs['PK_qa_pairs'].to_numpy().reshape(-1, 1)\n",
    "x_train = df_qa_pairs['vector'].to_numpy()\n",
    "y_category = df_qa_pairs['FK_category'].to_numpy().reshape(-1, 1)\n",
    "x_train = np.vstack(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi how may I help you: sdksdlk\n",
      "抱歉，我不懂你在說什麼\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "user_input = input('Hi how may I help you: ')\n",
    "user_input_processed = preprocess_all(user_input)\n",
    "user_input_vectorized = terms_to_vector(user_input_processed)\n",
    "user_vectorize_reshape = user_input_vectorized.reshape(1, -1)\n",
    "\n",
    "similarity = cosine_similarity(x_train, user_vectorize_reshape)\n",
    "PK_qa_pair = PK_question[np.argmax(similarity)]\n",
    "\n",
    "\n",
    "if y_category[np.argmax(similarity)].tolist()[0] == 18:\n",
    "    print('跳轉到編輯功能')\n",
    "else:\n",
    "    reply = df_qa_pairs['answer'][PK_qa_pair -1]\n",
    "    print(reply.values[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
