{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tripblog\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xA5x\\\\xA5_\\\\xBC\\\\xD0...' for column 'VARIABLE_VALUE' at row 1\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'cp950' codec can't encode character '\\u9519' in position 16: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2f8de7c38555>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chatbot_ch.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqa_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'cp950' codec can't encode character '\\u9519' in position 16: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as db\n",
    "import csv\n",
    "engine = db.create_engine('mysql+pymysql://root:root@localhost:3306/chatbot_chinese')\n",
    "conn = engine.connect()\n",
    "metadata = db.MetaData()\n",
    "table_category = db.Table('table_category_ch', metadata, autoload=True, autoload_with=engine)\n",
    "table_qa_pairs = db.Table('table_qa_pairs_ch', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# load sql data in table 'table_category' and 'table_qa_pairs'\n",
    "category = conn.execute(table_category.select()).fetchall()\n",
    "qa_pairs = conn.execute(table_qa_pairs.select()).fetchall()\n",
    "table_qa_pairs\n",
    "with open('chatbot_ch.csv','w',newline='') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(qa_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data in dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_qa_pairs = pd.DataFrame(qa_pairs)\n",
    "df_qa_pairs.columns = table_qa_pairs.columns.keys()\n",
    "category_dict = {i:category for (i, category) in category}\n",
    "\n",
    "with open('chatbot_ch.csv','w',newline='') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(df_qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.set_dictionary('dict.txt')\n",
    "with open('stops_specail.txt', 'r', encoding='utf8') as f: \n",
    "    stops = f.read().split('\\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\User\\Desktop\\Final-Project_TripBlog\\chatbot\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.u17c4573158338ce3b996b9f10ee53c44.cache\n",
      "Loading model cost 0.395 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "all_terms = []\n",
    "def preprocess(item):\n",
    "    terms = [t for t in jieba.cut(item, cut_all=False)]\n",
    "    all_terms.extend(terms)\n",
    "    return terms\n",
    "\n",
    "def preprocess_all(item):\n",
    "    terms = [t for t in jieba.cut(item, cut_all=True)]\n",
    "    all_terms.extend(terms)\n",
    "    return terms\n",
    "\n",
    "df_qa_pairs['processed'] = df_qa_pairs['question'].apply(preprocess_all)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(termindex) 885\n",
      "['', '見', '心煩', '業務', '可能', '是美', '冷戰', '心理', '那麼', '工作']\n"
     ]
    }
   ],
   "source": [
    "# 建立termindex: 將all_terms取出不重複的詞彙，並轉換型別為list(避免順序亂掉)\n",
    "termindex = list(set(all_terms))\n",
    "\n",
    "print(\"len(termindex)\", len(termindex))\n",
    "print(termindex[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885\n",
      "['', '見', '心煩', '業務', '可能', '是美', '冷戰', '心理', '那麼', '工作']\n",
      "[1.5733091883455947, 6.393590753950631, 6.393590753950631, 6.393590753950631, 6.393590753950631, 6.393590753950631, 6.393590753950631, 5.0072963928307415, 6.393590753950631, 6.393590753950631]\n"
     ]
    }
   ],
   "source": [
    "# 建立IDF vector\n",
    "Doc_Length = len(df_qa_pairs)  ## 計算出共有幾篇文章\n",
    "Idf_vector = []  ## 初始化IDF向量\n",
    "for term in termindex:  ## 對index中的詞彙跑回圈\n",
    "    num_of_doc_contains_term = 0  ## 計算有機篇文章出現過這個詞彙\n",
    "    for terms in df_qa_pairs['processed']:\n",
    "        if term in terms:\n",
    "            num_of_doc_contains_term += 1\n",
    "    idf = np.log(Doc_Length/num_of_doc_contains_term)  ## 計算該詞彙的IDF值\n",
    "    Idf_vector.append(idf)\n",
    "\n",
    "\n",
    "\n",
    "print(len(Idf_vector))\n",
    "print(termindex[:10])\n",
    "print(Idf_vector[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# 建立document vector\n",
    "def terms_to_vector(terms):  ## 定義把terms轉換成向量的function\n",
    "    ## 建立一條與termsindex等長、但值全部為零的向量(hint:dtype=np.float32)\n",
    "    vector = np.zeros_like(termindex, dtype=np.float32)  \n",
    "    \n",
    "    for term, count in Counter(terms).items():\n",
    "        # 計算vector上每一個字的tf值\n",
    "        try:\n",
    "            vector[termindex.index(term)] = count\n",
    "        except ValueError:\n",
    "            count = 0\n",
    "    \n",
    "    # 計算tfidf，element-wise的將vector與Idf_vector相乘\n",
    "    vector = vector * Idf_vector\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_qa_pairs['vector'] = df_qa_pairs['processed'].apply(terms_to_vector)  ## 將上面定義的function，套用在每一筆資料的terms欄位上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 885)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PK_question = df_qa_pairs['PK_qa_pairs'].to_numpy().reshape(-1, 1)\n",
    "x_train = df_qa_pairs['vector'].to_numpy()\n",
    "y_category = df_qa_pairs['FK_category'].to_numpy().reshape(-1, 1)\n",
    "x_train = np.vstack(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi how may I help you: 什麼是聊天機器人\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         3.75453342 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.68406055 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         5.70044357 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.81887978 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         5.70044357 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         3.8286414  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "聊天機器人是一個試圖模擬人類談話或'聊天'的程序,聊天機器人'eliza'是一個眾所周知的早期嘗試,創建的程序至少可以暫時愚弄一個真實的人類認為他們正在與另一個人交談。\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "user_input = input('Hi how may I help you: ')\n",
    "user_input_processed = preprocess_all(user_input)\n",
    "user_input_vectorized = terms_to_vector(user_input_processed)\n",
    "user_vectorize_reshape = user_input_vectorized.reshape(1, -1)\n",
    "print(user_vectorize_reshape)\n",
    "similarity = cosine_similarity(x_train, user_vectorize_reshape)\n",
    "PK_qa_pair = PK_question[np.argmax(similarity)]\n",
    "\n",
    "\n",
    "if y_category[np.argmax(similarity)].tolist()[0] == 18:\n",
    "    print('跳轉到編輯功能')\n",
    "else:\n",
    "    reply = df_qa_pairs['answer'][PK_qa_pair -1]\n",
    "    print(reply.values[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
